@inproceedings{dvorak2011, 
  author={Dvorak, Filip and Maschke, Jan and Vlcek, Cestmir}, 
  title={Response analysis of thermal field disturbance sensor}, 
  booktitle={Electro-Optical and Infrared Systems: Technology and Applications VIII}, 
  volume={8185}, 
  pages={96--103}, 
  year={2011}, 
  organization={SPIE} 
} 

@article{384017589,
author = {Sanabria, Melissa and Hirsch, Jonas and Poetsch, Anna},
year = {2024},
month = {09},
pages = {},
title = {Distinguishing word identity and sequence context in DNA language models},
volume = {25},
journal = {BMC Bioinformatics},
doi = {10.1186/s12859-024-05869-5}
}

@article{DBLP:journals/corr/abs-1810-04805,
  author       = {Jacob Devlin and
                  Ming{-}Wei Chang and
                  Kenton Lee and
                  Kristina Toutanova},
  title        = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                  Understanding},
  journal      = {CoRR},
  volume       = {abs/1810.04805},
  year         = {2018},
  url          = {http://arxiv.org/abs/1810.04805},
  eprinttype    = {arXiv},
  eprint       = {1810.04805},
  timestamp    = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{10.1093/bioinformatics/btab083,
    author = {Ji, Yanrong and Zhou, Zhihan and Liu, Han and Davuluri, Ramana V},
    title = {DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome},
    journal = {Bioinformatics},
    volume = {37},
    number = {15},
    pages = {2112-2120},
    year = {2021},
    month = {02},
    abstract = {Deciphering the language of non-coding DNA is one of the fundamental problems in genome research. Gene regulatory code is highly complex due to the existence of polysemy and distant semantic relationship, which previous informatics methods often fail to capture especially in data-scarce scenarios.To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, to capture global and transferrable understanding of genomic DNA sequences based on up and downstream nucleotide contexts. We compared DNABERT to the most widely used programs for genome-wide regulatory elements prediction and demonstrate its ease of use, accuracy and efficiency. We show that the single pre-trained transformers model can simultaneously achieve state-of-the-art performance on prediction of promoters, splice sites and transcription factor binding sites, after easy fine-tuning using small task-specific labeled data. Further, DNABERT enables direct visualization of nucleotide-level importance and semantic relationship within input sequences for better interpretability and accurate identification of conserved sequence motifs and functional genetic variant candidates. Finally, we demonstrate that pre-trained DNABERT with human genome can even be readily applied to other organisms with exceptional performance. We anticipate that the pre-trained DNABERT model can be fined tuned to many other sequence analyses tasks.The source code, pretrained and finetuned model for DNABERT are available at GitHub (https://github.com/jerryji1993/DNABERT).Supplementary data are available at Bioinformatics online.},
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btab083},
    url = {https://doi.org/10.1093/bioinformatics/btab083},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/37/15/2112/57195892/btab083.pdf},
}

@misc{zhou2024dnabert2efficientfoundationmodel,
      title={DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome}, 
      author={Zhihan Zhou and Yanrong Ji and Weijian Li and Pratik Dutta and Ramana Davuluri and Han Liu},
      year={2024},
      eprint={2306.15006},
      archivePrefix={arXiv},
      primaryClass={q-bio.GN},
      url={https://arxiv.org/abs/2306.15006}, 
}

@misc{sennrich2016neuralmachinetranslationrare,
      title={Neural Machine Translation of Rare Words with Subword Units}, 
      author={Rico Sennrich and Barry Haddow and Alexandra Birch},
      year={2016},
      eprint={1508.07909},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1508.07909}, 
}

@article{4c869e6d-8c66-3ab2-a976-761dca85164d,
 ISSN = {00030996},
 URL = {http://www.jstor.org/stable/29774782},
 author = {David B. Searls},
 journal = {American Scientist},
 number = {6},
 pages = {579--591},
 publisher = {Sigma Xi, The Scientific Research Society},
 title = {The Linguistics of DNA},
 urldate = {2025-06-07},
 volume = {80},
 year = {1992}
}


@article{10.1093/bioinformatics/bty1068,
    author = {Umarov, Ramzan and Kuwahara, Hiroyuki and Li, Yu and Gao, Xin and Solovyev, Victor},
    title = {Promoter analysis and prediction in the human genome using sequence-based deep learning models},
    journal = {Bioinformatics},
    volume = {35},
    number = {16},
    pages = {2730-2737},
    year = {2019},
    month = {01},
    abstract = {Computational identification of promoters is notoriously difficult as human genes often have unique promoter sequences that provide regulation of transcription and interaction with transcription initiation complex. While there are many attempts to develop computational promoter identification methods, we have no reliable tool to analyze long genomic sequences.In this work, we further develop our deep learning approach that was relatively successful to discriminate short promoter and non-promoter sequences. Instead of focusing on the classification accuracy, in this work we predict the exact positions of the transcription start site inside the genomic sequences testing every possible location. We studied human promoters to find effective regions for discrimination and built corresponding deep learning models. These models use adaptively constructed negative set, which iteratively improves the modelâ€™s discriminative ability. Our method significantly outperforms the previously developed promoter prediction programs by considerably reducing the number of false-positive predictions. We have achieved error-per-1000-bp rate of 0.02 and have 0.31 errors per correct prediction, which is significantly better than the results of other human promoter predictors.The developed method is available as a web server at http://www.cbrc.kaust.edu.sa/PromID/.},
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/bty1068},
    url = {https://doi.org/10.1093/bioinformatics/bty1068},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/35/16/2730/50719142/bty1068.pdf},
}